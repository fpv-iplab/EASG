{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "def clip_to_windows(root_folder):\n",
    "    result_dict = {}\n",
    "    for subdir, _, files in os.walk(root_folder):\n",
    "        for file in files:\n",
    "            if file.endswith(\".json\"):\n",
    "                annot_uid = os.path.basename(subdir)  # assuming annot_uid is the subfolder name\n",
    "                file_path = os.path.join(subdir, file)\n",
    "                with open(file_path, 'r') as json_file:\n",
    "                    data = json.load(json_file)\n",
    "                    \n",
    "                    clip_uid = data.get('clip_uid')\n",
    "                    pre_frame_number = data.get('pre_frame')['clip_frame_number']\n",
    "                    pnr_frame_number = data.get('pnr_frame')['clip_frame_number']\n",
    "                    post_frame_number = data.get('post_frame')['clip_frame_number']\n",
    "                    \n",
    "                    video_uid = data.get('video_uid')\n",
    "                    pre_frame_number_video = data.get('pre_frame_number')\n",
    "                    pnr_frame_number_video = data.get('pnr_frame_number')\n",
    "                    post_frame_number_video = data.get('post_frame_number')\n",
    "                    \n",
    "                    if video_uid:\n",
    "                        if video_uid not in result_dict:\n",
    "                            result_dict[video_uid] = {}\n",
    "                    result_dict[video_uid][annot_uid] = (pre_frame_number_video, post_frame_number_video)\n",
    "    return result_dict\n",
    "clip_2_frames = clip_to_windows('annotations_all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "FPS = 30\n",
    "W = 32\n",
    "S = 16\n",
    "\n",
    "import torch\n",
    "\n",
    "# Function to load the feature tensor and calculate the mean of relevant features\n",
    "def calculate_mean_feature(file_path, start_frame, end_frame, window_size=32, stride=16):\n",
    "    \n",
    "    # Calculate the number of features\n",
    "    num_features = features.shape[0]\n",
    "    \n",
    "    # Initialize a list to collect the relevant feature vectors\n",
    "    relevant_features = []\n",
    "    \n",
    "    # Iterate over each feature vector to check if it's in the specified range\n",
    "    for i in range(num_features):\n",
    "        # Calculate the frame range for the current feature\n",
    "        frame_start = i * stride\n",
    "        frame_end = frame_start + window_size\n",
    "        \n",
    "        # Check if the feature vector is in the specified range\n",
    "        if frame_end > start_frame and frame_start < end_frame:\n",
    "            # Check that the last frame does not exceed the end frame by more than 16\n",
    "            if frame_end > end_frame + 16:\n",
    "                continue\n",
    "            # Add the feature vector to the relevant features list\n",
    "            relevant_features.append(features[i])\n",
    "\n",
    "    # Convert the list of tensors to a tensor\n",
    "    relevant_features_tensor = torch.stack(relevant_features)\n",
    "    \n",
    "    # Calculate the mean of the relevant feature vectors\n",
    "    mean_feature = torch.mean(relevant_features_tensor, dim=0)\n",
    "    \n",
    "    return mean_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_dict = {}\n",
    "for clip_uid, data in clip_2_frames.items():\n",
    "    features = torch.load(\"slowfast8x8_r101_k400/{}.pt\".format(clip_uid))\n",
    "    for uid, window in data.items():\n",
    "        mean_fea = calculate_mean_feature(features, window[0], window[1])\n",
    "        res_dict[uid] = mean_fea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6250"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(res_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(res_dict, 'verb_features.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
